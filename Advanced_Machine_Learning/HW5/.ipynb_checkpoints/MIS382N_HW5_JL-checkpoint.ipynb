{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CfFH7xMgiLYK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ld3ZWXbOoTE8"
   },
   "source": [
    "# Question 1: Ensembles Conceptual (5 pts)\n",
    "Briefly describe the concepts of Gradient Boosting in your own words. How does it differ from Adaboost?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2c8qvF0Bq33L"
   },
   "source": [
    "## Answer:\n",
    "\n",
    "Gradient Boosting sequentially fits models, namely weak learners, on observations. Each (sequential) weak learner learns the residuals that the previous weak learner could not learn. A loss function is chosen for Gradient Boosting to optimize, and the method uses gradient descent in the function space to optimize. In Gradient Boosting, a variety of loss functions can be chosen. Gradient Boosting has the property of being an additive model as trees are added one at a time, and when that happens the gradient identifies the flaws of the previous models. While Gradient Boosting can overfit, it does reduce variance and bias. \n",
    "\n",
    "A major difference between Gradient Boosting and AdaBoost is that AdaBoost weights the observations the previous model missed where Gradient Boosting uses gradients in the loss function based on the residuals of the previous weak learner. Further AdaBoost assigns weights to each model's prediction, whereas Gradient Boosting does not weight models differently. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ftHMxZX1fnh"
   },
   "source": [
    "# Question 2: SVM (25 pts)\n",
    "Support Vector Machine (SVM) is a supervised machine learning algorithm that can be used for both classification and regression. In this problem, you will be playing with SVM on the sklearn wine dataset to explore the impacts of different parameters.\n",
    "\n",
    "**a) (5 pts)** Implement the `train_model()` function. This function takes as input:\n",
    "\n",
    "- X (the features)\n",
    "- y (the labels)\n",
    "- kernel (the specified kernel type, default value is `'linear'`)\n",
    "- C (the penalty parameter, default value is 1\n",
    ")\n",
    "- gamma (the kernel coefficient, default value is 0.5). \n",
    "\n",
    "The `train_model()` function should fit a [svm.SVC](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html) model and return the trained model. After implementing `train_model()`, use the `plot_model()` function provided below to plot the results of your model.\n",
    "\n",
    "**b) (10 pts)** The `kernel` parameter decides what form the input data will be transformed into, and may affect how your trained SVM model performs. In (a), the default value for `kernel` is `'linear'`, now re-train your svm model as you did in (a), but this time, use `'rbf'` as the `kernel`, while keeping `C=1, gamma=0.5` still. Use the provided `plot_model()` function to plot the results of your model. What do you observe?\n",
    "\n",
    "**c) (10 pts)** The `'gamma'` is a hyper-parameter needed for `'rbf'` kernel, which specifies the width of the Gaussian Kernel. Now experiment with different gamma values `[0.5, 1, 10, 100]`, use `'rbf'` as the `kernel`, while keeping `C=1`. Train your SVM and use the provided `plot_model()` function to plot the results of your model. What do you observe from the plot as gamma increases? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "pJxDghiN41EH"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# load data\n",
    "wine = datasets.load_wine()\n",
    "# only take the first two features\n",
    "X = wine.data[:, :2]\n",
    "y = wine.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "0ABf3DGRQ806"
   },
   "outputs": [],
   "source": [
    "def plot_model(X, y, svc, kernel='linear'):\n",
    "# You don't need to implement this function, this has been implemented and is just for plotting the trained model.\n",
    "\n",
    "# Input: \n",
    "#  - X: data features \n",
    "#  - y: the labels\n",
    "#  - svc: the trained svm.SVC model\n",
    "#  - kernel: specified kernel type, default value is 'linear'\n",
    "    x0_min, x0_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5\n",
    "    x1_min, x1_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5\n",
    "    h = (x0_max / x0_min)/100\n",
    "    xx0, xx1 = np.meshgrid(np.arange(x0_min, x0_max, h), np.arange(x1_min, x1_max, h))\n",
    "\n",
    "    plt.subplot(1, 1, 1)\n",
    "    y_pred = svc.predict(np.c_[xx0.ravel(), xx1.ravel()])\n",
    "    y_pred = y_pred.reshape(xx0.shape)\n",
    "    plt.contourf(xx0, xx1, y_pred, cmap=plt.cm.Paired, alpha=0.2)\n",
    "\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Paired)\n",
    "    plt.xlabel('Alcohol')\n",
    "    plt.ylabel('Malic Acid')\n",
    "    plt.xlim(xx0.min(), xx0.max())\n",
    "    plt.title('SVC with {} kernel'.format(kernel))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "h0gqCnvO5IJj"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-55bc908308cc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msvc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'linear'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplot_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msvc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'linear'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_model' is not defined"
     ]
    }
   ],
   "source": [
    "svc = train_model(X, y, kernel='linear', C=1, gamma=0.5)\n",
    "plot_model(X, y, svc, kernel='linear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TZX8qNFpDq0Z"
   },
   "source": [
    "## Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vYMiRB-C4-Cf"
   },
   "outputs": [],
   "source": [
    "def train_model(X, y, kernel='linear', C=1, gamma=0.5):\n",
    "    svc = svm.SVC(kernel=kernel, C=C, gamma=gamma)\n",
    "    svc.fit(X, y)\n",
    "    return svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = train_model(X, y)\n",
    "plot_model(X, y, svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = train_model(X, y, kernel='rbf')\n",
    "plot_model(X, y, svc, kernel='rbf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we see that the decision boundaries are non-linear under the rbf kernel compared to the linear kernel. Interestingly, the rbf, non-linear kernel, is able to capture some of the class boundary nuance better. Qualitatively, this appears to better classify classes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = train_model(X, y, kernel='rbf', gamma=0.5)\n",
    "plot_model(X, y, svc, kernel='rbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = train_model(X, y, kernel='rbf', gamma=1)\n",
    "plot_model(X, y, svc, kernel='rbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = train_model(X, y, kernel='rbf', gamma=10)\n",
    "plot_model(X, y, svc, kernel='rbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = train_model(X, y, kernel='rbf', gamma=100)\n",
    "plot_model(X, y, svc, kernel='rbf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As gamma increases, the decision boundaries become increasingly non-linear and separated out into different regions. It appears to better capture the classes even better as gamma increases. The class boundary fits are increasingly tighter, though, indicating possible overfitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QYLh0dv-P6nn"
   },
   "source": [
    "# Question 3: Ensemble methods for classification (25 pts)\n",
    "\n",
    "In this question, we will compare the performances of different ensemble methods for classification: Bagging, AdaBoost, GradientBoosting. \n",
    "\n",
    "The dataset used is [Spam Classification Data](https://archive.ics.uci.edu/ml/datasets/Spambase), which you can load from `spam_uci.csv` file. The last column represents the target label, where 1 means spam and 0 otherwise. You can use the provided codes to load the data and split training/test sets.\n",
    "\n",
    "**a) (5 pts)** Fit a [Decision Tree Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) with `random_state=10`,  and a [Logistic Regression Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) with `random_state=10` and `solver=\"newton-cg\"` for the spam classification problem. For each classifier, report the [accuracy_score](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html) and [roc_auc_score](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score) on the test data. \n",
    "**Note**: Before computing roc_auc_score, you will need [`predict_proba(X_test)[:, 1]`](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier.predict_proba) to obtain the predicted target scores first.\n",
    "\n",
    "\n",
    "**b) (5 pts)** For **each** classifier in (a), use [Bagging](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html) to create an ensemble of 50 classifiers (i.e `n_estimators=50`) with `random_state=10`, report the accuracy_score and roc_auc_score on the test data. Compare the scores with what you obtained in (a), briefly describe the impact of Bagging on both classifiers.\n",
    "\n",
    "\n",
    "**c) (5 pts)** Fit a [Random Forest Classifier](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) for the spam classification problem. Use [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) to find the best combination of hyperparameters from `{\"n_estimators\": [10, 100, 500], \"criterion\": ['gini', 'entropy'], \"random_state\": [42]}`. As what you did in (a), report the accuracy_score and roc_auc_score on the test data. \n",
    "\n",
    "\n",
    "**d) (6 pts)** Fit a [GradientBoosting Classifier](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html), and an [AdaBoost Classifier](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html#sklearn.ensemble.AdaBoostClassifier) for the spam classification problem. Use GridSearchCV to find the best combination of hyperparameters for each classifier: \n",
    "- For GradientBoosting, find the best combination from `{\"n_estimators\":[10, 100, 500], \"learning_rate\":[0.01, 0.1, 0.5], \"max_depth\":[3, 5, 10], \"subsample\":[0.5, 0.7, 1.0], \"random_state\":[42]}`;\n",
    "- For AdaBoost, find the best combination from `{\"n_estimators\":[10, 100, 500], \"learning_rate\":[0.01, 0.1, 0.5], \"random_state\":[42]}`. \n",
    "\n",
    "Report the accuracy_score and roc_auc_score on the test data for each classifier. The GridSearchCV may take some time, especially for GradientBoostingClassifier.\n",
    "\n",
    "**e) (4 pts)** In (c) and (d), you have obtained the best combination of hyperparameters respectively for Random Forest Classifier, Gradient Boosting Classifier and AdaBoost Classifier. \n",
    "\n",
    "Please use the best hyperparameters to initialize your classifiers, train your model, compute the accuracy_score and roc_auc_score on the test data, and plot the `accuracy_scores` of the three classifiers vs `n_estimators= [10, 100, 500]` in one plot, and plot the `roc_auc_scores` of the three classifiers vs `n_estimators= [10, 100, 500]` in another plot. That is, keep all other hyperparameters (except for `n_estimators`) as the best hyperparameters you obtained in (c) and (d), plot how the accuracy_score and roc_auc_score changes as you change the number of estimators (`n_estimators`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "mysVytBbQBKj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4601, 58)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "data = pd.read_csv('D:\\\\05_GitHub\\\\Data_Science_Projects\\\\Advanced_Machine_Learning\\\\HW5\\\\spam_uci.csv', index_col=0)\n",
    "print(data.shape)\n",
    "\n",
    "X = data.iloc[:, :56]\n",
    "y = data.iloc[:, 57]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F2UqIn87QBsK"
   },
   "source": [
    "## Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(random_state=10)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decision Tree classifier \n",
    "dt_clf = DecisionTreeClassifier(random_state=10)\n",
    "dt_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=10, solver='newton-cg')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression Classifier\n",
    "lr_clf = LogisticRegression(random_state=10, solver='newton-cg')\n",
    "lr_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions\n",
    "dt_preds = dt_clf.predict(X_test)\n",
    "lr_preds = lr_clf.predict(X_test)\n",
    "\n",
    "# get probabilities\n",
    "dt_probs = dt_clf.predict_proba(X_test)[:,1]\n",
    "lr_probs = lr_clf.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy:  0.9098090849242922\n",
      "Logistic Regression Accuracy:  0.9315339038841343\n"
     ]
    }
   ],
   "source": [
    "# Accuracy Scores\n",
    "print('Decision Tree Accuracy: ', accuracy_score(y_test, dt_preds))\n",
    "print('Logistic Regression Accuracy: ', accuracy_score(y_test, lr_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree ROC AUC Score:  0.9040453749567611\n",
      "Logistic Regression ROC AUC Score:  0.9734682742610166\n"
     ]
    }
   ],
   "source": [
    "# ROC AUC Scores\n",
    "print('Decision Tree ROC AUC Score: ', roc_auc_score(y_test, dt_probs))\n",
    "print('Logistic Regression ROC AUC Score: ', roc_auc_score(y_test, lr_probs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=DecisionTreeClassifier(random_state=10),\n",
       "                  n_estimators=50, random_state=10)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decision Tree Bagging\n",
    "dt_bag = BaggingClassifier(base_estimator=DecisionTreeClassifier(random_state=10), n_estimators=50, random_state=10)\n",
    "dt_bag.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=LogisticRegression(random_state=10,\n",
       "                                                    solver='newton-cg'),\n",
       "                  n_estimators=50, random_state=10)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression Bagging\n",
    "lr_bag = BaggingClassifier(base_estimator=LogisticRegression(random_state=10, solver='newton-cg'), n_estimators=50, random_state=10)\n",
    "lr_bag.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions\n",
    "dt_preds = dt_bag.predict(X_test)\n",
    "lr_preds = lr_bag.predict(X_test)\n",
    "\n",
    "# get probabilities\n",
    "dt_probs = dt_bag.predict_proba(X_test)[:,1]\n",
    "lr_probs = lr_bag.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Bagging Accuracy:  0.9368005266622779\n",
      "Logistic Regression Bagging Accuracy:  0.934167215273206\n"
     ]
    }
   ],
   "source": [
    "# Accuracy Scores\n",
    "print('Decision Tree Bagging Accuracy: ', accuracy_score(y_test, dt_preds))\n",
    "print('Logistic Regression Bagging Accuracy: ', accuracy_score(y_test, lr_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Bagging ROC AUC Score:  0.9796839729119637\n",
      "Logistic Regression Bagging ROC AUC Score:  0.97552769248874\n"
     ]
    }
   ],
   "source": [
    "# ROC AUC Scores\n",
    "print('Decision Tree Bagging ROC AUC Score: ', roc_auc_score(y_test, dt_probs))\n",
    "print('Logistic Regression Bagging ROC AUC Score: ', roc_auc_score(y_test, lr_probs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Bagging, both the Decision Tree and Logistic Regression classifier have improved accuracy and ROC AUC scores. The benefits of bagging (variance reduction and model stability) are clear in the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=RandomForestClassifier(),\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'n_estimators': [10, 100, 500], 'random_state': [42]})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\"n_estimators\": [10, 100, 500], \"criterion\": ['gini', 'entropy'], \"random_state\": [42]}\n",
    "rf = RandomForestClassifier()\n",
    "rf_clf = GridSearchCV(rf, params)\n",
    "rf_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions\n",
    "rf_preds = rf_clf.predict(X_test)\n",
    "\n",
    "# get probabilities\n",
    "rf_probs = rf_clf.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy:  0.9552337063857801\n",
      "Random Forest ROC AUC Score:  0.9891234188838844\n"
     ]
    }
   ],
   "source": [
    "# Accuracy Score\n",
    "print('Random Forest Accuracy: ', accuracy_score(y_test, rf_preds))\n",
    "# ROC AUC Scores\n",
    "print('Random Forest ROC AUC Score: ', roc_auc_score(y_test, rf_probs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting\n",
    "gb_params = [{\"n_estimators\":[10, 100, 500], \n",
    "                     \"learning_rate\":[0.01, 0.1, 0.5], \n",
    "                     \"max_depth\":[3, 5, 10], \n",
    "                     \"subsample\":[0.5, 0.7, 1.0], \n",
    "                     \"random_state\":[42]}]\n",
    "gb = GradientBoostingClassifier()\n",
    "gb_clf = GridSearchCV(gb, gb_params)\n",
    "gb_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AdaBoost\n",
    "ab_params = {\"n_estimators\":[10, 100, 500], \"learning_rate\":[0.01, 0.1, 0.5], \"random_state\":[42]}\n",
    "ab = AdaBoostClassifier()\n",
    "ab_clf = GridSearchCV(ab, ab_params)\n",
    "ab_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions\n",
    "gb_preds = gb_clf.predict(X_test)\n",
    "ab_preds = ab_clf.predict(X_test)\n",
    "\n",
    "# get probabilities\n",
    "gb_probs = gb_clf.predict_proba(X_test)[:,1]\n",
    "ab_probs = ab_clf.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy Scores\n",
    "print('Gradient Boosting Accuracy: ', accuracy_score(y_test, gb_preds))\n",
    "print('AdaBoost Accuracy: ', accuracy_score(y_test, ab_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC AUC Scores\n",
    "print('Gradient Boosting ROC AUC Score: ', roc_auc_score(y_test, gb_probs))\n",
    "print('AdaBoost ROC AUC Score: ', roc_auc_score(y_test, ab_probs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**e**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['Random Forest', 'Gradient Boosting', 'AdaBoost']*3\n",
    "accuracy_scores = []\n",
    "roc_auc_scores = []\n",
    "estimators= [10, 10, 10, 100, 100, 100, 500, 500, 500]\n",
    "n_estimators= [10, 100, 500]\n",
    "for n in n_estimators:\n",
    "    rf = RandomForestClassifier(criterion='gini', random_state=42, n_estimators=n)\n",
    "    gb = GradientBoostingClassifier(learning_rate = 0.1, max_depth = 3, random_state=42, subsample=1, n_estimators=n)\n",
    "    ab = AdaBoostClassifier(learning_rate=0.1, random_state=42, n_estimators=n)\n",
    "    \n",
    "    rf.fit(X_train, y_train)\n",
    "    gb.fit(X_train, y_train)\n",
    "    ab.fit(X_train, y_train)\n",
    "    \n",
    "    # get predictions\n",
    "    rf_preds = rf.predict(X_test)\n",
    "    gb_preds = gb.predict(X_test)\n",
    "    ab_preds = ab.predict(X_test)\n",
    "\n",
    "    # get probabilities\n",
    "    rf_probs = rf.predict_proba(X_test)[:,1]\n",
    "    gb_probs = gb.predict_proba(X_test)[:,1]\n",
    "    ab_probs = ab.predict_proba(X_test)[:,1]\n",
    "    \n",
    "    # accuracy scores\n",
    "    accuracy_scores.append(accuracy_score(y_test, rf_preds))\n",
    "    accuracy_scores.append(accuracy_score(y_test, gb_preds))\n",
    "    accuracy_scores.append(accuracy_score(y_test, ab_preds))\n",
    "    \n",
    "    # roc auc scores\n",
    "    roc_auc_scores.append(roc_auc_score(y_test, rf_probs))\n",
    "    roc_auc_scores.append(roc_auc_score(y_test, gb_probs))\n",
    "    roc_auc_scores.append(roc_auc_score(y_test, ab_probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy score plot\n",
    "accuracy_df = pd.DataFrame({'models':models, 'accuracy':accuracy_scores, 'roc_auc':roc_auc_scores, 'estimators':estimators})\n",
    "accuracy_df.set_index('estimators', inplace=True);\n",
    "accuracy_df.groupby('models')['accuracy'].plot(legend=True);\n",
    "plt.title('Accuracy vs Estimators');\n",
    "plt.xlabel('N Estimators');\n",
    "plt.ylabel('Accuracy');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roc auc score plot\n",
    "roc_auc_df = pd.DataFrame({'models':models, 'accuracy':accuracy_scores, 'roc_auc':roc_auc_scores, 'estimators':estimators})\n",
    "roc_auc_df.set_index('estimators', inplace=True);\n",
    "roc_auc_df.groupby('models')['roc_auc'].plot(legend=True);\n",
    "plt.title('ROC AUC Score vs Estimators');\n",
    "plt.xlabel('N Estimators');\n",
    "plt.ylabel('ROC AUC Score');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "MIS382N-HW5 Questions.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
