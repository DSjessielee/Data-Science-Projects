{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nb3QnVJJbF-b"
   },
   "source": [
    "# <p style=\"text-align: center;\">MIS 382N: Advanced Machine Learning</p>\n",
    "# <p style=\"text-align: center;\">Homework 3</p>\n",
    "## <p style=\"text-align: center;\">Total points: 85</p>\n",
    "## <p style=\"text-align: center;\">Due: Monday, **Oct 15th** submitted via Canvas by 11:59 pm</p>\n",
    "\n",
    "Your homework should be written in a **Jupyter notebook**. Please make sure your code runs and the graphics (and anything else) are displayed in your notebook before submitting (%matplotlib inline). \n",
    "\n",
    "**Note: Notebooks MUST have the images embedded in them. There will be no regrades if attached images do not render in the notebook. Please re download from canvas after submission and make sure all attached images render without errors. (Hint: Image module from IPython.display)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wkXOyWSCbMlw"
   },
   "source": [
    "**This can be an individual assignment or group of 2. If you choose to do it as a group, please specify who you are working with (name and EID), then only one student should submit the homework. Put your name and eid here.**\n",
    "\n",
    "Name:\n",
    "\n",
    "EID:\n",
    "\n",
    "Name:\n",
    "\n",
    "EID:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7LgyLF87bPkA"
   },
   "source": [
    "# Question 1: Stochastic gradient descent II (20 pts)\n",
    "\n",
    "Write an SGD solution in Python to the non-linear model without using any other library except for those provided in the code template below. \n",
    "\n",
    "$$ y = w_0 + w_1x_1 + w_2x_1x_2 + w_3x_1^2x_2 + w_4x_1x_2^2 + w_5x_2^3$$ \n",
    "\n",
    "The solution class template is given. The `init()` function of the class takes as input the `learning_rate`, `regularization_constant` and `number_of_epochs`. The `fit()` method must take as input `X`, `y` and `update_rule` which can be `'sgd_momentum'` or `'RMSprop'`. The `predict()` method takes an `X` value (optionally, an array of values). \n",
    "\n",
    "Use your new gradient descent regression to train your model and predict the data given in 'SGD_samples.csv', for 30 epochs, using learning rates: `[0.0001, 0.001, 0.01, 0.05]` and regularization (ridge regression) constants: `[0, 0.01, 0.1]`. **(8 points)** \n",
    "\n",
    "Plot MSE and the $w$ parameters as a function of epoch (for 30 epochs) for the best 2 combinations of `learning_rate` and `regularization_constant` for SGD-Momentum, RMSprop, i.e., for each combination, you should have one plot for MSE vs Epoch and another for the parameters(weights) vs Epoch using respectively SGD-Momentum and RMSprop, hence in total 8 plots. Report the `learning_rate`, `regularization_constant` and MSE at the end of 30 epochs for the two best combinations for SGD-Momentum and RMSprop respectively. **($4\\times 2 = 8$ pts)**\n",
    "\n",
    "Observe the results, compare the performance of the two learning methods **(4 pts)**. \n",
    "\n",
    "Here is a blog which you can go through to know about RMSprop and Adam - [blog](http://ruder.io/optimizing-gradient-descent/).\n",
    "\n",
    "Following codes are for your reference, please don't change the initialization values of the given parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "XVVk-mks4laL"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "class LinearRegression:\n",
    "    \n",
    "    def __init__(self, learning_rate, regularization, n_epoch):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_epoch = n_epoch\n",
    "        self.regularization = regularization\n",
    "        self.coef = np.zeros(5) # coefficient vector\n",
    "        self.eps = 10**-8 # only used in adagrad\n",
    "        self.cache = np.zeros(self.coef.shape) # only used in adagrad\n",
    "        self.mu = 0.9 # used in momentum\n",
    "\n",
    "    def rmsprop(self, gradient):\n",
    "        '''\n",
    "        updates self.coef based on gradient using rmsprop\n",
    "        '''\n",
    "        self.coef = self.coef - self.learning_rate * gradient\n",
    "    \n",
    "    def sgd_momentum(self, gradient):\n",
    "        '''\n",
    "        updates self.coef based on gradient using Sgd_momentum\n",
    "        '''\n",
    "    \n",
    "    def fit(self, X, y, update_rule='sgd_momentum', plot=False):\n",
    "        '''\n",
    "        Fit the model given X, y. It uses the specified update_rule\n",
    "        and displays a plot of the coefficients vs epochs, and mse vs epochs if plot is set as True. \n",
    "        \n",
    "        -> use get_features to get the features from X\n",
    "        -> for epoch in epochs:\n",
    "            iterate through all x, y.\n",
    "                compute prediction using linearPredict.\n",
    "                compute gradient.\n",
    "                pass this gradient to the corresponding update function and update the coefficients\n",
    "                keep track of mse and coefficients\n",
    "        -> plot if required\n",
    "        \n",
    "        '''\n",
    "\n",
    "    def get_features(self, X):\n",
    "       '''\n",
    "       X (input) is the nx2 dimensional array - n data points with X_1 and X_2.\n",
    "       It returns a nX5 dimensional array - n data points with 1, X_1, X_1X_2, X_1^2X_2^2, X_2^3.\n",
    "       '''\n",
    "        \n",
    "    def linearPredict(self, X_features):\n",
    "       '''\n",
    "       returns the dot product of X and self.coef\n",
    "       '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "XE3pcI6O7Jvj"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-58-25e79b7f35f7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Only use this code block if you are using Google Colab.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# If you are using Jupyter Notebook, please ignore this code block. You can directly upload the file to your Jupyter Notebook file systems.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m## It will prompt you to select a local file. Click on “Choose Files” then select and upload the file.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "# Only use this code block if you are using Google Colab.\n",
    "# If you are using Jupyter Notebook, please ignore this code block. You can directly upload the file to your Jupyter Notebook file systems.\n",
    "from google.colab import files\n",
    "\n",
    "## It will prompt you to select a local file. Click on “Choose Files” then select and upload the file. \n",
    "## Wait for the file to be 100% uploaded. You should see the name of the file once Colab has uploaded it.\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KMCFUos-5Brh"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "num_terms = 6\n",
    "\n",
    "data = pd.read_csv('SGD_samples.csv')\n",
    "X = np.array([data['x1'].values, data['x2'].values]).T\n",
    "y = data['y'].values\n",
    "n_epochs = 30\n",
    "learning_rate = [0.0001, 0.001, 0.01, 0.05]\n",
    "regularization = [0, 0.01, 0.1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d0xrLYAi3GtV"
   },
   "source": [
    "# Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H6pUQ7SvbU4G"
   },
   "source": [
    "#Question 2: Tensorflow Playground (15 pts)\n",
    "\n",
    "In this question, you will be playing with [Tensorflow Playground](https://playground.tensorflow.org).\n",
    "\n",
    "Select \"**Classification**\" as the **Problem Type**. Among the four datasets shown in DATA, please select the **top right** dataset. \n",
    "\n",
    "Use the following settings as the DEFAULT settings for all **subquestions**: Learning rate = 0.03, Activation = Tanh, Regularization = None, Ratio of training to test data = 50%, Noise = 0, Batch Size = 30, input as $X_1$ with $X_2$, One hidden layer with two neurons.\n",
    "\n",
    "a) **(4 pts)** Use the DEFAULT setting and run two experiments - one using **Tanh** as the activation function and one using the **Linear** activation function. Report the train, test losses for both at the end of **1000 epochs**. What qualitative difference do you observe in the decision boundaries obtained? What do you think is the reason for this? \n",
    "\n",
    "We will now study the effect of certain variations in the network structure or training process, keeping all other aspects the same as in the DEFAULT setting specified above, with **Tanh** as the activation.\n",
    "\n",
    "b) **(4 pts)** Effect of number of hidden units: Keep other settings the same as in DEFAULT, report the training loss and test loss at the end of 1000 epochs **using 4 neurons and 8 neurons in the hidden layer**. What do you observe in terms of the decision boundary obtained as the number of neurons increases? What do you think is the reason for this? \n",
    "\n",
    "c) **(4 pts)** Effect of Learning rate and number of epochs: Keep other settings the same as in DEFAULT, change the Activation to **ReLU** and use **4 neurons** in the hidden layer. For learning rate 10, 1, 0.1, 0.01 and 0.001, report the train, test losses at the end of **100 epochs**, **1000 epochs** respectively. What do you observe from the change of loss vs learning rate, and the change of loss vs epoch numbers? \n",
    "\n",
    "d) **(3 pts)** Use the DEFAULT setting. Play around with any hyperparameters, network architectures or input features (such as $\\sin(X_1), X_1^2$ etc.), and report the best train and test loss you obtain (test loss should be no greater than 0.06). Attach the screenshot showing your full network, output and the parameters. Briefly justify your results, and comment on what helps/what doesn't help with lowering the loss, etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l85_A1P33Nr4"
   },
   "source": [
    "# Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rYljtggnkSzl"
   },
   "source": [
    "# Question 3: Outlier detection using PyOD (30 pts)\n",
    "\n",
    "Oulier detection, or anomaly detection is usually an unsupervised learning task where the objective is to identify suspicious observations in data. It has been widely used in military surveillance for enemy activities to prevent attacks, intrusion detection in cyber security, fraud detection for credit cards, etc.\n",
    "\n",
    "PyOD is a comprehensive and scalable Python library for detecting outlying objects in multivariate data. PyOD includes more than 30 detection algorithms and provides unified APIs which makes it quite handy to use. In this question, you will play with PyOD, explore three different outlier detection algorithms and compare their performances. First let's install PyOD.\n",
    "\n",
    "```\n",
    "# install pyod using pip first\n",
    "!pip install pyod\n",
    "```\n",
    "\n",
    "You can load the data stored in 'Q3_train_dataset.csv' and 'Q3_test_dataset.csv' using the following codes.\n",
    "\n",
    "```\n",
    "import pandas as pd\n",
    "# Load data code goes here\n",
    "train_df = pd.read_csv('Q3_train_dataset.csv')\n",
    "test_df = pd.read_csv('Q3_test_dataset.csv')\n",
    "\n",
    "X_train = train_df[['X_train_0', 'X_train_1', 'X_train_2', 'X_train_3', 'X_train_4']].to_numpy()\n",
    "y_train = train_df[['y_train']].to_numpy()\n",
    "X_test = test_df[['X_test_0', 'X_test_1', 'X_test_2', 'X_test_3', 'X_test_4']].to_numpy()\n",
    "y_test = test_df[['y_test']].to_numpy()\n",
    "```\n",
    "\n",
    " `X_train` and `X_test` contain the features, with the dimension of 5. `y_train` and `y_test` store the outlier labels, 0 means normal data, 1 means outlier data. \n",
    " \n",
    "a) **(5 pts)** **Fit `X_train` to a linear outlier detection model Minimum Covariance Determinant (MCD) using PyOD**, this [page](https://pyod.readthedocs.io/en/latest/pyod.models.html#module-pyod.models.mcd) will provide some functions you may need. \n",
    "\n",
    "```\n",
    "from pyod.models.mcd import MCD\n",
    "clf = MCD() # initialize MCD class using the default parameters\n",
    "\n",
    "# YOUR CODE SHOULD COME HERE, FIT THE MODEL USING X_TRAIN\n",
    "```\n",
    "**Use the fitted model to predict the outlier labels of `X_test`. Compute the raw outlier scores on `X_test` using `decision_function()`.**\n",
    "\n",
    "**Run PyOD's `evaluate_print()` function using the test set ground truth outlier labels and the raw outlier scores predicted by the model, to compute the ROC and Precision@n results .** \n",
    "\n",
    "```\n",
    "from pyod.utils.data import evaluate_print\n",
    "```\n",
    "\n",
    "b) **(5 pts)** `X_train` and `X_test` are 5-dimension features, which makes it impossible to visualize them in Euclidean plane. But we can use Principal Component Analysis (PCA) to reduce the dimensions of `X_train` and `X_test` to 2, and then plot them. You may want to use `fit_and_transform()` function.\n",
    "\n",
    "\n",
    "```\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "# Fit pca to X_train and X_test and transform \n",
    "train_principalComponents = # IMPLEMENT\n",
    "test_principalComponents = # IMPLEMENT\n",
    "```\n",
    "\n",
    "After reducing the dimension to 2, now you can visualize the outliers using PyOD's `visualize()` function. Please plot the visualization. You may find [this](https://pyod.readthedocs.io/en/latest/pyod.utils.html#module-pyod.utils.example) useful on how to use `visualize()` .\n",
    "\n",
    "```\n",
    "from pyod.utils.example import visualize\n",
    "```\n",
    "\n",
    "Now you should be able to observe the ground truth outliers and the outliers predicted by the model.\n",
    "\n",
    "\n",
    "c) **(20 pts)** Apply the same process as in (a) and (b) to the following two models, and visualize the outlier results. Please compare the performance of the three models in terms of their ROC, Precision@n, and what you observe from the three visualizations.\n",
    "\n",
    "*   [Proximity-Based model - Clustering Based Local Outlier Factor (CBLOF)](https://pyod.readthedocs.io/en/latest/pyod.models.html#module-pyod.models.cblof)\n",
    "*   [Probabilistic model - Copula-based Outlier Detection (COPOD)](https://pyod.readthedocs.io/en/latest/pyod.models.html#module-pyod.models.copod)\n",
    "\n",
    "```\n",
    "from pyod.models.cblof import CBLOF\n",
    "from pyod.models.copod import COPOD\n",
    "```\n",
    "\n",
    "# Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BULJ0M0sL1gf"
   },
   "outputs": [],
   "source": [
    "# install pyod using pip first\n",
    "!pip install pyod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qEY5NClZL9a8"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Load data code goes here\n",
    "train_df = pd.read_csv('Q3_train_dataset.csv')\n",
    "test_df = pd.read_csv('Q3_test_dataset.csv')\n",
    "\n",
    "X_train = train_df[['X_train_0', 'X_train_1', 'X_train_2', 'X_train_3', 'X_train_4']].to_numpy()\n",
    "y_train = train_df[['y_train']].to_numpy()\n",
    "X_test = test_df[['X_test_0', 'X_test_1', 'X_test_2', 'X_test_3', 'X_test_4']].to_numpy()\n",
    "y_test = test_df[['y_test']].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oRPwxrFQL_Y3"
   },
   "outputs": [],
   "source": [
    "# (a)\n",
    "from pyod.models.mcd import MCD\n",
    "clf = MCD() # initialize MCD class using the default parameters\n",
    "\n",
    "# fit the model using X_train\n",
    "\n",
    "# YOUR CODE SHOULD COME HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pwFvjZQ5MBE_"
   },
   "outputs": [],
   "source": [
    "from pyod.utils.data import evaluate_print\n",
    "# predict the outlier labels of X_test using the trained model, compute the raw outlier scores on X_test using decision_function()\n",
    "# then use evaluate_print() to print out the evaluation results\n",
    "\n",
    "# YOUR CODE SHOULD COME HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RBIhWWz-MC1C"
   },
   "outputs": [],
   "source": [
    "# (b)\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "# Fit pca to X_train and X_test and transform \n",
    "train_principalComponents = # YOUR CODE SHOULD COME HERE\n",
    "test_principalComponents = # YOUR CODE SHOULD COME HERE\n",
    "\n",
    "from pyod.utils.example import visualize\n",
    "# Visualize the ground truth outliers and predicted outliers using visualize()\n",
    "\n",
    "# YOUR CODE SHOULD COME HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dSs_Kej_MIN5"
   },
   "outputs": [],
   "source": [
    "# (c)\n",
    "from pyod.models.cblof import CBLOF\n",
    "from pyod.models.copod import COPOD\n",
    "\n",
    "# YOUR CODE SHOULD COME HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "98Ipdr7rbdal"
   },
   "source": [
    "# Question 4: PCA Conceptual questions (5 pts)\n",
    "Explain the principle of Principal Component Analysis algorithm, especially why we can select the best projection bases based on the covariance matrix of data from the perspective of optimization?\n",
    "\n",
    "# Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " N-dimensional data will result in NxN symetric covariance matrix where the diagnal is the variance of each dimension.\n",
    " \n",
    "  \\begin{matrix}\n",
    "  cov(x_{1}x_{1}) & cov(x_{1}x_{2}) & cov(x_{1}x_{3}) ... & cov(x_{1}x_{n}) \\\\\n",
    "  cov(x_{2}x_{1}) & cov(x_{2}x_{2}) & cov(x_{2}x_{3}) ... & cov(x_{2}x_{n}) \\\\\n",
    "  cov(x_{3}x_{1}) & cov(x_{3}x_{2}) & cov(x_{3}x_{3}) ... & cov(x_{3}x_{n}) \\\\\n",
    "  ...    &  ...   &  ...       & ...     \\\\\n",
    "  cov(x_{n}x_{1}) & cov(x_{n}x_{2}) & cov(x_{n}x_{3}) ... & cov(x_{n}x_{n}) \n",
    "   \\end{matrix}\n",
    "\n",
    "This covariance matrix needs to be decomposed to find eigenvectors and eigenvalues, where we find that the eigenvectors with the largest eigenvalues correspond to the dimensions that have the strongest correlation in the dataset, which is the principal component.\n",
    "\n",
    "PCA finds the best “subspace” that captures as much data variance as possible, to retain as much information as possible from the original dataset, where the dimention is reduced. The 1st PCA captures \n",
    " \n",
    "matrix\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a7LS1E520XPL"
   },
   "source": [
    "\n",
    "\n",
    "# Question 5: Pre-processing and sampling (15 pts)\n",
    "\n",
    "The following dataset contains House prices describing the sales of individual residential property in Ames, Iowa data with explanatory variables describing almost every aspect of residential homes and dependent variable being SalePrice. Here, some cells of most columns in the dataset contain NaN values.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HzXBJJihpKum"
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import scipy.stats as stats\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(100)\n",
    "\n",
    "data = pd.read_csv(\"sales_data.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SZpAfufgqDnc"
   },
   "source": [
    "\n",
    "a) **(2 pts)** Print the number of NaN values in each column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "4ZJ-OvcIO9bW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSSubClass          0\n",
      "MSZoning            0\n",
      "LotFrontage       259\n",
      "LotArea             0\n",
      "Alley            1369\n",
      "OverallQual         0\n",
      "OverallCond         0\n",
      "YearBuilt           0\n",
      "YearRemodAdd        0\n",
      "MasVnrArea          8\n",
      "ExterQual           0\n",
      "BsmtFinSF1          0\n",
      "BsmtFinSF2          0\n",
      "BsmtUnfSF           0\n",
      "TotalBsmtSF         0\n",
      "HeatingQC           0\n",
      "CentralAir          0\n",
      "Electrical          1\n",
      "1stFlrSF            0\n",
      "2ndFlrSF            0\n",
      "LowQualFinSF        0\n",
      "GrLivArea           0\n",
      "BsmtFullBath        0\n",
      "BsmtHalfBath        0\n",
      "FullBath            0\n",
      "HalfBath            0\n",
      "BedroomAbvGr        0\n",
      "KitchenAbvGr        0\n",
      "KitchenQual         0\n",
      "TotRmsAbvGrd        0\n",
      "Functional          0\n",
      "Fireplaces          0\n",
      "FireplaceQu       690\n",
      "GarageType         81\n",
      "GarageYrBlt        81\n",
      "GarageCars          0\n",
      "GarageArea          0\n",
      "WoodDeckSF          0\n",
      "OpenPorchSF         0\n",
      "EnclosedPorch       0\n",
      "3SsnPorch           0\n",
      "ScreenPorch         0\n",
      "PoolArea            0\n",
      "PoolQC           1453\n",
      "Fence            1179\n",
      "MiscFeature      1406\n",
      "MiscVal             0\n",
      "MoSold              0\n",
      "YrSold              0\n",
      "SalePrice           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2qX1tYc9PTeq"
   },
   "source": [
    "b) **(3 pts)** Create a copy of `data`, and name it `data_dm`, then create a new column in `data_dm` named `binned_yr_built` and apply binning to the column `yr_built`. Use `pandas.cut()` and modify its paramter list as below:\n",
    "\n",
    "```\n",
    "bins=[1900, 1920, 1940, 1960, 1980, 2000, 2020]\n",
    "labels=['1900-1920', '1920-1940', '1940-1960', '1960-1980', '1980-2000', '2000-2020']\n",
    "include_lowest=True\n",
    "```\n",
    "Next, perform one-hot encoding on this new column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "id": "f5JLgp3ePXaH"
   },
   "outputs": [],
   "source": [
    "data_dm=data.copy()\n",
    "data_dm['binned_yr_built']=pd.cut(data_dm['YearBuilt'],\n",
    "                                  bins=[1900, 1920, 1940, 1960, 1980, 2000, 2020],\n",
    "                                  labels=['1900-1920', '1920-1940', '1940-1960', '1960-1980','1980-2000', '2000-2020'],\n",
    "                                  include_lowest=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MSSubClass         False\n",
       "MSZoning           False\n",
       "LotFrontage        False\n",
       "LotArea            False\n",
       "Alley               True\n",
       "OverallQual        False\n",
       "OverallCond        False\n",
       "YearBuilt          False\n",
       "YearRemodAdd       False\n",
       "MasVnrArea         False\n",
       "ExterQual          False\n",
       "BsmtFinSF1         False\n",
       "BsmtFinSF2         False\n",
       "BsmtUnfSF          False\n",
       "TotalBsmtSF        False\n",
       "HeatingQC          False\n",
       "CentralAir         False\n",
       "Electrical         False\n",
       "1stFlrSF           False\n",
       "2ndFlrSF           False\n",
       "LowQualFinSF       False\n",
       "GrLivArea          False\n",
       "BsmtFullBath       False\n",
       "BsmtHalfBath       False\n",
       "FullBath           False\n",
       "HalfBath           False\n",
       "BedroomAbvGr       False\n",
       "KitchenAbvGr       False\n",
       "KitchenQual        False\n",
       "TotRmsAbvGrd       False\n",
       "Functional         False\n",
       "Fireplaces         False\n",
       "FireplaceQu        False\n",
       "GarageType         False\n",
       "GarageYrBlt        False\n",
       "GarageCars         False\n",
       "GarageArea         False\n",
       "WoodDeckSF         False\n",
       "OpenPorchSF        False\n",
       "EnclosedPorch      False\n",
       "3SsnPorch          False\n",
       "ScreenPorch        False\n",
       "PoolArea           False\n",
       "PoolQC              True\n",
       "Fence               True\n",
       "MiscFeature         True\n",
       "MiscVal            False\n",
       "MoSold             False\n",
       "YrSold             False\n",
       "SalePrice          False\n",
       "binned_yr_built    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dm.isna().sum()>=len(data_dm)*0.65"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DZG-thPCPe8J"
   },
   "source": [
    "\n",
    "c) **(2 pts)** Drop the columns which have more than 65 percentage of missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "4wwgOq-_PlXV"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', 'OverallQual',\n",
       "       'OverallCond', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'ExterQual',\n",
       "       'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'HeatingQC',\n",
       "       'CentralAir', 'Electrical', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF',\n",
       "       'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath',\n",
       "       'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual', 'TotRmsAbvGrd',\n",
       "       'Functional', 'Fireplaces', 'GarageType', 'GarageYrBlt', 'GarageCars',\n",
       "       'GarageArea', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch',\n",
       "       'ScreenPorch', 'PoolArea', 'MiscVal', 'MoSold', 'YrSold', 'SalePrice',\n",
       "       'binned_yr_built'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dm=data_dm.dropna(thresh=len(data_dm)*0.65, axis=1)\n",
    "len(data_dm.columns)\n",
    "data_dm.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1F_Tj5rtPSLw"
   },
   "source": [
    "\n",
    "d) **(3 pts)** Take a sample of 800 rows at random and compute its mean, compare this value with the population mean.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "id": "LqijYNMkPS-a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>population_mean</th>\n",
       "      <th>sample_mean</th>\n",
       "      <th>diff in %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MSSubClass</th>\n",
       "      <td>56.897260</td>\n",
       "      <td>54.456250</td>\n",
       "      <td>-4.290207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LotFrontage</th>\n",
       "      <td>70.049958</td>\n",
       "      <td>70.500000</td>\n",
       "      <td>0.642458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LotArea</th>\n",
       "      <td>10516.828082</td>\n",
       "      <td>10917.616250</td>\n",
       "      <td>3.810923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OverallQual</th>\n",
       "      <td>6.099315</td>\n",
       "      <td>6.076250</td>\n",
       "      <td>-0.378158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OverallCond</th>\n",
       "      <td>5.575342</td>\n",
       "      <td>5.585000</td>\n",
       "      <td>0.173219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YearBuilt</th>\n",
       "      <td>1971.267808</td>\n",
       "      <td>1970.491250</td>\n",
       "      <td>-0.039394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <td>1984.865753</td>\n",
       "      <td>1984.900000</td>\n",
       "      <td>0.001725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MasVnrArea</th>\n",
       "      <td>103.685262</td>\n",
       "      <td>94.958595</td>\n",
       "      <td>-8.416497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <td>443.639726</td>\n",
       "      <td>422.495000</td>\n",
       "      <td>-4.766193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <td>46.549315</td>\n",
       "      <td>49.912500</td>\n",
       "      <td>7.224993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <td>567.240411</td>\n",
       "      <td>586.693750</td>\n",
       "      <td>3.429470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <td>1057.429452</td>\n",
       "      <td>1059.101250</td>\n",
       "      <td>0.158100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1stFlrSF</th>\n",
       "      <td>1162.626712</td>\n",
       "      <td>1171.187500</td>\n",
       "      <td>0.736332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <td>346.992466</td>\n",
       "      <td>348.098750</td>\n",
       "      <td>0.318821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LowQualFinSF</th>\n",
       "      <td>5.844521</td>\n",
       "      <td>8.245000</td>\n",
       "      <td>41.072308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GrLivArea</th>\n",
       "      <td>1515.463699</td>\n",
       "      <td>1527.531250</td>\n",
       "      <td>0.796294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <td>0.425342</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>-3.607085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <td>0.057534</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>4.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FullBath</th>\n",
       "      <td>1.565068</td>\n",
       "      <td>1.552500</td>\n",
       "      <td>-0.803063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HalfBath</th>\n",
       "      <td>0.382877</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>1.860465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <td>2.866438</td>\n",
       "      <td>2.873750</td>\n",
       "      <td>0.255078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KitchenAbvGr</th>\n",
       "      <td>1.046575</td>\n",
       "      <td>1.041250</td>\n",
       "      <td>-0.508835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <td>6.517808</td>\n",
       "      <td>6.561250</td>\n",
       "      <td>0.666509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fireplaces</th>\n",
       "      <td>0.613014</td>\n",
       "      <td>0.617500</td>\n",
       "      <td>0.731844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageYrBlt</th>\n",
       "      <td>1978.506164</td>\n",
       "      <td>1977.769737</td>\n",
       "      <td>-0.037221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageCars</th>\n",
       "      <td>1.767123</td>\n",
       "      <td>1.746250</td>\n",
       "      <td>-1.181202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageArea</th>\n",
       "      <td>472.980137</td>\n",
       "      <td>469.008750</td>\n",
       "      <td>-0.839652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <td>94.244521</td>\n",
       "      <td>97.320000</td>\n",
       "      <td>3.263298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <td>46.660274</td>\n",
       "      <td>45.477500</td>\n",
       "      <td>-2.534863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <td>21.954110</td>\n",
       "      <td>23.793750</td>\n",
       "      <td>8.379481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3SsnPorch</th>\n",
       "      <td>3.409589</td>\n",
       "      <td>3.041250</td>\n",
       "      <td>-10.803033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ScreenPorch</th>\n",
       "      <td>15.060959</td>\n",
       "      <td>13.955000</td>\n",
       "      <td>-7.343217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PoolArea</th>\n",
       "      <td>2.758904</td>\n",
       "      <td>2.143750</td>\n",
       "      <td>-22.297046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MiscVal</th>\n",
       "      <td>43.489041</td>\n",
       "      <td>47.462500</td>\n",
       "      <td>9.136690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MoSold</th>\n",
       "      <td>6.321918</td>\n",
       "      <td>6.248750</td>\n",
       "      <td>-1.157367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YrSold</th>\n",
       "      <td>2007.815753</td>\n",
       "      <td>2007.837500</td>\n",
       "      <td>0.001083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SalePrice</th>\n",
       "      <td>180921.195890</td>\n",
       "      <td>181643.962500</td>\n",
       "      <td>0.399493</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               population_mean    sample_mean  diff in %\n",
       "MSSubClass           56.897260      54.456250  -4.290207\n",
       "LotFrontage          70.049958      70.500000   0.642458\n",
       "LotArea           10516.828082   10917.616250   3.810923\n",
       "OverallQual           6.099315       6.076250  -0.378158\n",
       "OverallCond           5.575342       5.585000   0.173219\n",
       "YearBuilt          1971.267808    1970.491250  -0.039394\n",
       "YearRemodAdd       1984.865753    1984.900000   0.001725\n",
       "MasVnrArea          103.685262      94.958595  -8.416497\n",
       "BsmtFinSF1          443.639726     422.495000  -4.766193\n",
       "BsmtFinSF2           46.549315      49.912500   7.224993\n",
       "BsmtUnfSF           567.240411     586.693750   3.429470\n",
       "TotalBsmtSF        1057.429452    1059.101250   0.158100\n",
       "1stFlrSF           1162.626712    1171.187500   0.736332\n",
       "2ndFlrSF            346.992466     348.098750   0.318821\n",
       "LowQualFinSF          5.844521       8.245000  41.072308\n",
       "GrLivArea          1515.463699    1527.531250   0.796294\n",
       "BsmtFullBath          0.425342       0.410000  -3.607085\n",
       "BsmtHalfBath          0.057534       0.060000   4.285714\n",
       "FullBath              1.565068       1.552500  -0.803063\n",
       "HalfBath              0.382877       0.390000   1.860465\n",
       "BedroomAbvGr          2.866438       2.873750   0.255078\n",
       "KitchenAbvGr          1.046575       1.041250  -0.508835\n",
       "TotRmsAbvGrd          6.517808       6.561250   0.666509\n",
       "Fireplaces            0.613014       0.617500   0.731844\n",
       "GarageYrBlt        1978.506164    1977.769737  -0.037221\n",
       "GarageCars            1.767123       1.746250  -1.181202\n",
       "GarageArea          472.980137     469.008750  -0.839652\n",
       "WoodDeckSF           94.244521      97.320000   3.263298\n",
       "OpenPorchSF          46.660274      45.477500  -2.534863\n",
       "EnclosedPorch        21.954110      23.793750   8.379481\n",
       "3SsnPorch             3.409589       3.041250 -10.803033\n",
       "ScreenPorch          15.060959      13.955000  -7.343217\n",
       "PoolArea              2.758904       2.143750 -22.297046\n",
       "MiscVal              43.489041      47.462500   9.136690\n",
       "MoSold                6.321918       6.248750  -1.157367\n",
       "YrSold             2007.815753    2007.837500   0.001083\n",
       "SalePrice        180921.195890  181643.962500   0.399493"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(6)\n",
    "sample_ages = np.random.choice(a= data['SalePrice'], size=800)\n",
    "#Sample mean\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "data_dm = shuffle(data_dm)\n",
    "\n",
    "sample_mean=data_dm[:800].mean(axis=0, skipna=True,numeric_only=True)\n",
    "population_mean=data_dm.mean(axis=0, skipna=True,numeric_only=True)\n",
    "#Population mean\n",
    "sample_mean.append(population_mean)\n",
    "\n",
    "mean_compare=pd.concat({'population_mean':population_mean,'sample_mean':sample_mean},axis=1)\n",
    "mean_compare['diff in %']=(mean_compare['sample_mean']/mean_compare['population_mean']-1)*100\n",
    "mean_compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2FfEuB-hQ9a5"
   },
   "source": [
    "e) **(2pts)** Calculate the 95% confidence intervals for SalePrice with a sample size of 100. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "id": "nrXDpIsgUhPs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% confidence_interval is: (174380.3010998981, 200514.5589001019)\n",
      "True mean value is: 180921.19589041095\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(10)\n",
    "sample_size = 100\n",
    "sample = np.random.choice(a= data_dm['SalePrice'],\n",
    "                          size = sample_size)\n",
    "sample_mean = sample.mean()\n",
    "\n",
    "#Get the critical Z value\n",
    "\n",
    "from scipy.stats import norm\n",
    "\n",
    "z_critical  = norm.ppf(0.95)\n",
    "\n",
    "# define probability\n",
    "\n",
    "p = 0.95\n",
    "\n",
    "# retrieve value <= probability\n",
    "\n",
    "\n",
    "#Get population standard deviation\n",
    "\n",
    "pop_stdev=data_dm['SalePrice'].std()\n",
    "\n",
    "#margin of error\n",
    "margin_of_error = z_critical * (pop_stdev/math.sqrt(sample_size)) \n",
    "\n",
    "#confidence interval\n",
    "confidence_interval = (sample_mean - margin_of_error,\n",
    "                       sample_mean + margin_of_error)  \n",
    "\n",
    "#Print confidence interval and true mean value\n",
    "\n",
    "print('95% confidence_interval is: {}'.format(confidence_interval))\n",
    "print('True mean value is: {}'.format(data_dm['SalePrice'].mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(3pts)** Calculate the 95% confidence intervals for 100 different trials with a sample size of 500. Plot the confidence intervals and interpret how it captures the population mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "id": "vpX5NGr0VhyM"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 936x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(12)\n",
    "\n",
    "sample_size = 500\n",
    "\n",
    "intervals = []\n",
    "sample_means = []\n",
    "\n",
    "for sample in range(100):\n",
    "    sample = np.random.choice(a= data_dm['SalePrice'], size = sample_size)\n",
    "    sample_mean = sample.mean()\n",
    "    sample_means.append(sample_mean)\n",
    "   \n",
    "    # compute z critical value\n",
    "    z_critical  = norm.ppf(0.95)   \n",
    "\n",
    "    # compute population standard deviation\n",
    "    pop_stdev=data_dm['SalePrice'].std()\n",
    "  \n",
    "    margin_of_error = z_critical * (pop_stdev/math.sqrt(sample_size))\n",
    "    confidence_interval = (sample_mean - margin_of_error,\n",
    "                           sample_mean + margin_of_error)  \n",
    "    \n",
    "    intervals.append(confidence_interval)\n",
    "    \n",
    "plt.figure(figsize=(13, 9))\n",
    "\n",
    "plt.errorbar(x=np.arange(0.1, 100, 1), \n",
    "             y=sample_means, \n",
    "             yerr=[(top-bot)/2 for top,bot in intervals],\n",
    "             fmt='o')\n",
    "\n",
    "plt.hlines(xmin=0, xmax=100,\n",
    "           y=data['SalePrice'].mean(), \n",
    "           linewidth=2.0,\n",
    "           color=\"red\")\n",
    "plt.title('Confidence Intervals for 100 Trials', fontsize = 20)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "MIS382N-HW3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
